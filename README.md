# Plateforme e-learning RAG + Llama 3 70B (Groq)

Ce projet est une plateforme e-learning basÃ©e sur le Retrieval-Augmented Generation (RAG) avec FastAPI, une interface web interactive, et l'intÃ©gration du modÃ¨le Llama 3 70B via l'API Groq. Il permet de questionner des documents de formation (PDF) et d'obtenir des rÃ©ponses enrichies par l'IA.

---

## ğŸš€ FonctionnalitÃ©s
- Extraction automatique du texte depuis des PDF
- Chunking intelligent des documents
- GÃ©nÃ©ration d'embeddings et indexation vectorielle (FAISS)
- Recherche sÃ©mantique de passages pertinents
- Orchestration RAG + LLM (Llama 3 70B via Groq)
- Interface web de chat moderne (FastAPI + HTML/CSS/JS)

---

## ğŸ“ Structure du projet

```
Stage/
â”‚
â”œâ”€â”€ app.py                # Serveur FastAPI (chat web)
â”œâ”€â”€ chat.py               # Script CLI pour tester le RAG
â”œâ”€â”€ chunking.py           # DÃ©coupage des textes en chunks
â”œâ”€â”€ embed.py              # GÃ©nÃ©ration des embeddings
â”œâ”€â”€ llama3_client.py      # Appel Ã  l'API Groq (LLM)
â”œâ”€â”€ parser.py             # Extraction texte PDF â†’ TXT
â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â”œâ”€â”€ search_engine.py      # Recherche de similaritÃ©
â”œâ”€â”€ vectordb.py           # Gestion de la base vectorielle
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html        # Frontend web (chat)
â”‚
â”œâ”€â”€ data/                 # (Placez vos PDF ici)
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

1. **Cloner le dÃ©pÃ´t**
2. **CrÃ©er un environnement virtuel**
   ```bash
   python -m venv venv
   source venv/bin/activate  # ou venv\Scripts\activate sous Windows
   ```
3. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```
4. **Obtenir une clÃ© API Groq**
   - Inscrivez-vous sur https://console.groq.com/ et copiez votre clÃ© API.

---

## ğŸ”‘ Variables d'environnement

DÃ©finissez la clÃ© API Groq avant de lancer le chat :
```bash
# Sous Linux/Mac
export GROQ_API_KEY="votre_cle_groq"
# Sous Windows PowerShell
$env:GROQ_API_KEY="votre_cle_groq"
```

---

## ğŸ› ï¸ Pipeline d'utilisation

1. **Placez vos PDF dans le dossier `data/`**
2. **Extraction du texte**
   ```bash
   python parser.py
   ```
3. **DÃ©coupage en chunks**
   ```bash
   python chunking.py
   ```
4. **GÃ©nÃ©ration des embeddings**
   ```bash
   python embed.py
   ```
5. **Lancer le chat web**
   ```bash
   uvicorn app:app --reload
   # Ouvrez http://localhost:8000 dans votre navigateur
   ```
6. **(Optionnel) Tester en ligne de commande**
   ```bash
   python chat.py
   ```

---

## ğŸ’¡ Exemple d'utilisation

- Posez une question sur le contenu de vos PDF via l'interface web ou le script CLI.
- L'IA recherche les passages pertinents et gÃ©nÃ¨re une rÃ©ponse pÃ©dagogique.

---

## ğŸ“ Personnalisation
- Modifiez `static/index.html` pour adapter le style du chat.
- Adaptez les scripts pour d'autres formats (PPTX, DOCX, etc.).
- Ajoutez des endpoints FastAPI pour l'upload, l'historique, etc.

---

## ğŸ§¹ Bonnes pratiques
- **Ne pas versionner** : `venv/`, `dataembeddings/`, `datatxt/`, `datachunks/`, `*.npy`, `*.json` gÃ©nÃ©rÃ©s, `faiss.index`, etc.
- Utilisez `.gitignore` pour garder le dÃ©pÃ´t propre.

---

## ğŸ“„ Licence
MIT
